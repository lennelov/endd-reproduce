The VGG16 architecture used by Malinin is based on the one provided by the torch.models
package.

This model is a sequential model with a predefined set of layers. The below function is responsible
for layer creation:

    def make_layers(cfg, batch_norm=False):
        layers = []
        in_channels = 3
        for v in cfg:
            if v == 'M':
                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]
            else:
                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)
                if batch_norm:
                    layers += [conv2d, nn.BatchNorm2d(v), nn.LeakyReLU(negative_slope=0.2, inplace=True), nn.Dropout(p=dropout_rate)]
                else:
                    layers += [conv2d, nn.LeakyReLU(negative_slope=0.2, inplace=True), nn.Dropout(p=dropout_rate)]
                in_channels = v
        return nn.Sequential(*layers)

As we can see, the parameters cfg and batch_norm determine the architecture. batch_norm is a bool,
and cfg is a list. There are four possible configurations, contained in the below dictionary:

    cfgs = {
        'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
        'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],
        'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],
        'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],
    }


From inspection of https://github.com/KaosEngineer/PriorNetworks/blob/master/prior_networks/models/my_vgg.py
we can see that list 'D' corresponds to VGG16. We can also see that Malinin uses a (custom?) top
layer. This represents the "Top block" in the layers list below:


layers = [
  # Block 1
  Conv2d(3, 64, kernel_size=3, padding=1),
  BatchNorm2d(64),
  LeakyReLU(0.2),
  Dropout(0.2),

  Conv2d(64, 64, kernel_size=3, padding=1),
  BatchNorm2d(64),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),

  # Block 2
  Conv2d(64, 128, kernel_size=3, padding=1),
  BatchNorm2d(128),
  LeakyReLU(0.2),
  Dropout(0.2),

  Conv2d(128, 128, kernel_size=3, padding=1),
  BatchNorm2d(128),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),

  # Block 3
  Conv2d(128, 256, kernel_size=3, padding=1),
  BatchNorm2d(256),
  LeakyReLU(0.2),
  Dropout(0.2),

  Conv2d(256, 256, kernel_size=3, padding=1),
  BatchNorm2d(256),
  LeakyReLU(0.2),
  Dropout(0.2),

  Conv2d(256, 256, kernel_size=3, padding=1),
  BatchNorm2d(256),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),

  # Block 4
  Conv2d(256, 512, kernel_size=3, padding=1),
  BatchNorm2d(512),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),
  Conv2d(512, 512, kernel_size=3, padding=1),
  BatchNorm2d(512),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),
  Conv2d(512, 512, kernel_size=3, padding=1),
  BatchNorm2d(512),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),

  # Block 5
  Conv2d(512, 512, kernel_size=3, padding=1),
  BatchNorm2d(512),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),
  Conv2d(512, 512, kernel_size=3, padding=1),
  BatchNorm2d(512),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),
  Conv2d(512, 512, kernel_size=3, padding=1),
  BatchNorm2d(512),
  LeakyReLU(0.2),
  Dropout(0.2),

  MaxPool2d(kernel_size=2, stride=2),

  # Top block
  AdaptiveAvgPool2d((7, 7)),
  Flatten(1),
  nn.Linear(512 * 7 * 7, 2048),
  nn.LeakyReLU(0.2),
  nn.Dropout(0.3),
  nn.Linear(2048, 2048),
  nn.LeakyReLU(0.2),
  nn.Dropout(0.3),
  nn.Linear(2048, num_classes)

]
